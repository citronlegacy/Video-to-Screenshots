{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# WIP Duplicate Image Deleter\n",
        "\n",
        "| |GitHub| Colab | |\n",
        "|:--|:-:|:-:|:-:|\n",
        "| ðŸŽ¬ **Video To Screenshots** | [![GitHub](https://img.shields.io/badge/GitHub-Visit-brightgreen.svg)](https://github.com/citronlegacy/Video-to-Screenshots/blob/main/Video-to-Screenshots.ipynb) | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/citronlegacy/Video-to-Screenshots/blob/main/Video-to-Screenshots.ipynb) |\n",
        "| ðŸŽ¬ **Youtube Video to Screenshots** | [![GitHub](https://img.shields.io/badge/GitHub-Visit-brightgreen.svg)](https://github.com/citronlegacy/Video-to-Screenshots/blob/main/Youtube-Video-to-Screenshots.ipynb) | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/citronlegacy/Video-to-Screenshots/blob/main/Youtube-Video-to-Screenshots.ipynb) |\n",
        "\n",
        "### Project Description\n",
        "\n",
        "This Google Colab notebook is a project for generating frames from a video. It can take a video file as input and output a screenshot every frame or every n frames.\n",
        "I recommend not outputting every frame as it would generate thousands of images for even a few minutes of video.\n",
        "\n",
        "Copied the some code from https://github.com/Maximax67/LoRA-Dataset-Automaker\n",
        "\n",
        "### Libraries Used\n",
        "\n",
        "- **FFmpeg:** A multimedia framework for handling audio, video, and other multimedia files.\n",
        "- **tqdm:** A library for displaying progress bars in Python.\n",
        "- **subprocess:** A module to spawn new processes, connect to their input/output/error pipes, and obtain their return codes.\n",
        "- **shlex:** A module for parsing strings into tokens, especially useful when dealing with command-line-like syntax.\n",
        "- **os:** A module for interacting with the operating system, providing functionality to manage directories and files.\n",
        "- **ipywidgets:** A library for creating interactive widgets in Jupyter notebooks.\n",
        "- **pytube:** A library for downloading YouTube videos.\n",
        "- **zipfile:** A module to work with zip archives in Python.\n",
        "\n",
        "\n",
        "### Project Disclaimer\n",
        "\n",
        "This Colab notebook is provided for educational and informational purposes only. The content and code within this notebook are not intended for production use, and any actions taken based on the provided information are at your own risk.\n",
        "When using the `pytube` library to download videos from YouTube, please be aware of YouTube's terms of service. Unauthorized downloading of videos may violate YouTube's terms.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HpxHK_zyJloG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lqVkdVbnnXm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Install requirements and connect to Google Drive\n",
        "\n",
        "import time\n",
        "import os\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display, Markdown\n",
        "from google.colab.output import clear as clear_output\n",
        "!apt-get install ffmpeg\n",
        "import subprocess\n",
        "import shlex\n",
        "import re\n",
        "!pip install tqdm\n",
        "from tqdm import tqdm\n",
        "from ipywidgets import widgets\n",
        "!pip install pytube\n",
        "from pytube import YouTube\n",
        "import zipfile\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  print(\"ðŸ“‚ Connecting to Google Drive...\")\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "def check_directory_exists(directory_path):\n",
        "    return os.path.exists(directory_path) and os.path.isdir(directory_path)\n",
        "\n",
        "def countNumberOfFilesInFolder(folder):\n",
        "  count = 0\n",
        "  # Iterate directory\n",
        "  for f in os.listdir(folder):\n",
        "      # check if current path is a file and also not a .txt file\n",
        "      if (os.path.isfile(os.path.join(folder, f))):\n",
        "          count += 1\n",
        "  return count\n",
        "\n",
        "def clean_string(input_string):\n",
        "    # Remove special characters\n",
        "    cleaned_string = re.sub(r'[^\\w\\s]', '', input_string)\n",
        "\n",
        "    # Replace whitespaces with underscores\n",
        "    cleaned_string = cleaned_string.replace(' ', '_')\n",
        "\n",
        "    return cleaned_string\n",
        "\n",
        "\n",
        "def get_file_size(file_path):\n",
        "    try:\n",
        "        size_bytes = os.path.getsize(file_path)\n",
        "        size_kilobytes = size_bytes / 1024.0\n",
        "        size_megabytes = size_kilobytes / 1024.0\n",
        "        size_gigabytes = size_megabytes / 1024.0\n",
        "\n",
        "        print(f\"File Size: {size_kilobytes:.2f} KB | {size_megabytes:.2f} MB | {size_gigabytes:.2f} GB\")\n",
        "        return size_bytes\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def zip_folder(folder_path, zip_path):\n",
        "    try:\n",
        "        with zipfile.ZipFile(f\"{zip_path}.zip\", 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "            total_files = sum([len(files) for root, dirs, files in os.walk(folder_path)])\n",
        "\n",
        "            with tqdm(total=total_files, desc=\"Zipping\", unit=\"file\") as pbar:\n",
        "                for foldername, subfolders, filenames in os.walk(folder_path):\n",
        "                    for filename in filenames:\n",
        "                        file_path = os.path.join(foldername, filename)\n",
        "                        arcname = os.path.relpath(file_path, folder_path)\n",
        "                        zipf.write(file_path, arcname=arcname)\n",
        "                        pbar.update(1)\n",
        "\n",
        "        print(f\"\\nFolder '{folder_path}' \\nSuccessfully zipped to '{zip_path}.zip'\")\n",
        "        zipfileReference = zip_path +\".zip\"\n",
        "        get_file_size(zipfileReference)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Install Successfull!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Install requirements and connect to Google Drive\n",
        "!pip install fiftyone\n",
        "import os\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from fiftyone import ViewField as VF\n",
        "import shutil\n",
        "from google.colab.output import clear as clear_output\n",
        "import zipfile\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  print(\"ðŸ“‚ Connecting to Google Drive...\")\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "def countNumberOfFilesInFolder(folder):\n",
        "  count = 0\n",
        "  # Iterate directory\n",
        "  for f in os.listdir(folder):\n",
        "      # check if current path is a file and also not a .txt file\n",
        "      if (os.path.isfile(os.path.join(folder, f))):\n",
        "          count += 1\n",
        "  return count\n",
        "\n",
        "def delete_dir(directory):\n",
        "  try:\n",
        "      # Delete the directory and its contents\n",
        "      shutil.rmtree(directory)\n",
        "      print(f\"Directory '{directory}' deleted successfully.\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error deleting directory '{directory}': {e}\")\n",
        "\n",
        "def get_file_size(file_path):\n",
        "    try:\n",
        "        size_bytes = os.path.getsize(file_path)\n",
        "        size_kilobytes = size_bytes / 1024.0\n",
        "        size_megabytes = size_kilobytes / 1024.0\n",
        "        size_gigabytes = size_megabytes / 1024.0\n",
        "\n",
        "        print(f\"File Size: {size_kilobytes:.2f} KB | {size_megabytes:.2f} MB | {size_gigabytes:.2f} GB\")\n",
        "        return size_bytes\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def zip_folder(folder_path, zip_path):\n",
        "    try:\n",
        "        with zipfile.ZipFile(f\"{zip_path}.zip\", 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "            total_files = sum([len(files) for root, dirs, files in os.walk(folder_path)])\n",
        "\n",
        "            with tqdm(total=total_files, desc=\"Zipping\", unit=\"file\") as pbar:\n",
        "                for foldername, subfolders, filenames in os.walk(folder_path):\n",
        "                    for filename in filenames:\n",
        "                        file_path = os.path.join(foldername, filename)\n",
        "                        arcname = os.path.relpath(file_path, folder_path)\n",
        "                        zipf.write(file_path, arcname=arcname)\n",
        "                        pbar.update(1)\n",
        "\n",
        "        print(f\"\\nFolder '{folder_path}' \\nSuccessfully zipped to '{zip_path}.zip'\")\n",
        "        zipfileReference = zip_path +\".zip\"\n",
        "        get_file_size(zipfileReference)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "clear_output()\n",
        "print(\"Install Successfull!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YGH6xQ1ot96v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Detect and Delete Duplicates in Directory\n",
        "#@markdown This works best with GPU - You may want to back up files in Google Drive and swtich to a GPU instance for this part\n",
        "\n",
        "image_directory_location = \"Directory in Google Drive (/content/drive/MyDrive/)\" #@param [\"Directory in Colab (/content/)\", \"Directory in Google Drive (/content/drive/MyDrive/)\"]\n",
        "#@markdown This is the folder were your images folder is and the place where the filtered output folder will be created\n",
        "project_name = \"video2screens\" #@param {type:\"string\"}\n",
        "#@markdown This is the folder with your images\n",
        "image_directory_name = \"Barbara__Genshin_Impact_PUBG_Samsara_Dancemp4_output\" #@param {type:\"string\"}\n",
        "filtered_directory_name = image_directory_name + \"_filtered\"\n",
        "\n",
        "# Set working folder\n",
        "if \"Google Drive\" in image_directory_location:\n",
        "    directory_location = os.path.join(\"/content/drive/MyDrive/\", project_name)\n",
        "else:\n",
        "    directory_location = os.path.join(\"/content\", project_name)\n",
        "\n",
        "working_folder = os.path.join(directory_location, image_directory_name)\n",
        "#working_folder = directory_location\n",
        "\n",
        "\n",
        "assert working_folder, f\"Error: {working_folder} does not exist\"\n",
        "filtered_dir = os.path.join(directory_location, filtered_directory_name)\n",
        "\n",
        "\n",
        "#@markdown This is how similar images should be for marking them to delete. I recommend 0.96 to 0.99 based on your needs:\n",
        "similarity_threshold = 0.98 # @param {type:\"number\"}\n",
        "\n",
        "#@markdown Batch sizes, if you don't know what it is, better don't touch:\n",
        "embedding_batch_size = 200 # @param {type:\"integer\"}\n",
        "similarity_matrix_batch_size = 1000 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown Clip model name. You can choose another model from fiftyone zoo if you want. Just print its name here.\n",
        "model_name = \"clip-vit-base32-torch\" # @param {type:\"string\"}\n",
        "\n",
        "print (\"Detecting Duplicates!\")\n",
        "print (f\"There are {countNumberOfFilesInFolder(working_folder)} images in the working folder\")\n",
        "dataset = fo.Dataset.from_dir(working_folder, dataset_type=fo.types.ImageDirectory)\n",
        "\n",
        "# @markdown This cell will load the images, make embeddings using the selected model, calculate the similarity matrix and find samples to remove.\n",
        "\n",
        "def make_embeddings(model_name, batch_size):\n",
        "    model = foz.load_zoo_model(model_name)\n",
        "    embeddings = dataset.compute_embeddings(model, batch_size=batch_size)\n",
        "\n",
        "    # Unload the model from the GPU to free up memory\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "def calculate_similarity_matrix(embeddings, batch_size):\n",
        "    batch_size = min(embeddings.shape[0], batch_size)\n",
        "    batch_embeddings = np.array_split(embeddings, batch_size)\n",
        "    similarity_matrices = []\n",
        "\n",
        "    # Find the maximum size of the arrays\n",
        "    max_size_x = max(array.shape[0] for array in batch_embeddings)\n",
        "    max_size_y = max(array.shape[1] for array in batch_embeddings)\n",
        "\n",
        "    for batch_embedding in batch_embeddings:\n",
        "        similarity = cosine_similarity(batch_embedding)\n",
        "        # Pad 0 for np.concatenate\n",
        "        padded_array = np.zeros((max_size_x, max_size_y))\n",
        "        padded_array[0:similarity.shape[0], 0:similarity.shape[1]] = similarity\n",
        "        similarity_matrices.append(padded_array)\n",
        "\n",
        "    # Concatenate the padded arrays\n",
        "    similarity_matrix = np.concatenate(similarity_matrices, axis=0)\n",
        "    similarity_matrix = similarity_matrix[0:embeddings.shape[0], 0:embeddings.shape[0]]\n",
        "\n",
        "    similarity_matrix = cosine_similarity(embeddings)\n",
        "    similarity_matrix -= np.identity(len(similarity_matrix))\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "def make_samples(dataset, similarity_matrix, threshold=0.98):\n",
        "    dataset.match(VF(\"max_similarity\") > threshold)\n",
        "    dataset.tags = [\"delete\", \"has_duplicates\"]\n",
        "    id_map = [s.id for s in dataset.select_fields([\"id\"])]\n",
        "    samples_to_remove = set()\n",
        "    samples_to_keep = set()\n",
        "    for idx, sample in enumerate(dataset):\n",
        "      if sample.id not in samples_to_remove:\n",
        "        # Keep the first instance of two duplicates\n",
        "        samples_to_keep.add(sample.id)\n",
        "\n",
        "        dup_idxs = np.where(similarity_matrix[idx] > threshold)[0]\n",
        "        for dup in dup_idxs:\n",
        "            # We kept the first instance so remove all other duplicates\n",
        "            samples_to_remove.add(id_map[dup])\n",
        "        if len(dup_idxs) > 0:\n",
        "            sample.tags.append(\"has_duplicates\")\n",
        "            sample.save()\n",
        "      else:\n",
        "        sample.tags.append(\"delete\")\n",
        "        sample.save()\n",
        "\n",
        "    return samples_to_remove, samples_to_keep\n",
        "\n",
        "\n",
        "embeddings = make_embeddings(model_name, embedding_batch_size)\n",
        "\n",
        "clear_output()\n",
        "print(\"Embeddings calculated!\")\n",
        "\n",
        "similarity_matrix = calculate_similarity_matrix(embeddings, similarity_matrix_batch_size)\n",
        "print(\"Similarity matrix calculated!\")\n",
        "\n",
        "samples_to_remove, samples_to_keep = make_samples(dataset, similarity_matrix, similarity_threshold)\n",
        "print(f\"Remove percentage: {len(samples_to_remove) / (len(samples_to_remove) + len(samples_to_keep)) * 100}\")\n",
        "\n",
        "del embeddings, similarity_matrix, samples_to_remove, samples_to_keep\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "session = None\n",
        "print(\"Detection Done!\")\n",
        "print(\"_\" *50)\n",
        "print(\"Deleting Duplicates...\")\n",
        "\n",
        "# @markdown Delete all images marked as \"delete\".\n",
        "\n",
        "# @markdown If you want to delete previous images in the folder (if you run this cell before), select this:\n",
        "delete_previous_filtered_images = True # @param {type:\"boolean\"}\n",
        "zip_filtered_output = True # @param {type:\"boolean\"}\n",
        "\n",
        "os.makedirs(filtered_dir, exist_ok=True)\n",
        "\n",
        "if (delete_previous_filtered_images):\n",
        "    delete_dir(filtered_dir)\n",
        "\n",
        "kys = [s for s in dataset if \"delete\" in s.tags]\n",
        "dataset.delete_samples(kys)\n",
        "n_filtered = len(dataset)\n",
        "dataset.export(export_dir=filtered_dir, dataset_type=fo.types.ImageDirectory)\n",
        "\n",
        "if session is not None:\n",
        "    session.refresh()\n",
        "    fo.close_app()\n",
        "\n",
        "#clear_output()\n",
        "\n",
        "print(\"Done! Dataset filtered from %d duplicates! Total %d images left!\" % (len(kys), n_filtered))\n",
        "print(f\"Filtered directory is {filtered_dir}\")\n",
        "\n",
        "\n",
        "if (zip_filtered_output):\n",
        "  print(\"_\" * 50) #Print Horizontal bar\n",
        "  zip_filtered_output_storage_location = \"Store in Google Drive (/content/drive/MyDrive/)\" #@param [\"Store in colab (/content/)\", \"Store in Google Drive (/content/drive/MyDrive/)\"]\n",
        "\n",
        "  if zip_filtered_output_storage_location == \"Store in colab (/content/)\":\n",
        "      # Code for storing in colab session\n",
        "      storage_path = \"/content/\"\n",
        "      output_zip_directory = os.path.join(storage_path, project_name)\n",
        "      print(f\"Zipping output in Google Drive: {output_zip_directory}\")\n",
        "\n",
        "  elif zip_filtered_output_storage_location == \"Store in Google Drive (/content/drive/MyDrive/)\":\n",
        "      # Code for storing in Google Drive\n",
        "      storage_path = \"/content/drive/MyDrive/\"\n",
        "      output_zip_directory = os.path.join(storage_path, project_name)\n",
        "      print(f\"Zipping output in Google Colab: {output_zip_directory}\")\n",
        "\n",
        "  folder_to_zip = filtered_dir\n",
        "  zip_output_path = os.path.join(output_zip_directory, filtered_directory_name)\n",
        "\n",
        "  zip_folder(folder_to_zip, zip_output_path)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "chwNQn_wuCDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Get a Youtube Video\n",
        "#@markdown Define your folder in Colab or Google Drive\n",
        "# Set variables\n",
        "input_storage_location = \"Video file in Google Drive (/content/drive/MyDrive/)\" #@param [\"Video file in Colab (/content/)\", \"Video file in Google Drive (/content/drive/MyDrive/)\"]\n",
        "project_name = \"video2screens\" #@param {type:\"string\"}\n",
        "\n",
        "# Set working folder\n",
        "if \"Video file in Google Drive\" in input_storage_location:\n",
        "    working_folder = os.path.join(\"/content/drive/MyDrive/\", project_name)\n",
        "else:\n",
        "    working_folder = os.path.join(\"/content\", project_name)\n",
        "\n",
        "# Check if the working_folder exists, create if not\n",
        "if not os.path.exists(working_folder):\n",
        "    os.makedirs(working_folder)\n",
        "\n",
        "# YouTube video URL\n",
        "youtube_video_url = \"https://www.youtube.com/watch?v=aaXC_KFsJmg\"  #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# Download the video\n",
        "try:\n",
        "    yt = YouTube(youtube_video_url)\n",
        "    video_stream = yt.streams.get_highest_resolution()\n",
        "    video_stream.download(output_path=working_folder)\n",
        "    print(f\"Video downloaded successfully to: {os.path.join(working_folder, yt.title)}\")\n",
        "    video_file_name = f\"{yt.title}.mp4\"\n",
        "    print(f\"Video File name: {video_file_name}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YXCwi0gWYjtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@markdown ### Get Screenshots for a Video\n",
        "\n",
        "# Define a function to check if a directory exists\n",
        "def check_directory_exists(directory):\n",
        "    return os.path.exists(directory)\n",
        "\n",
        "# Set the working_folder based on input_storage_location\n",
        "if \"Video file in Google Drive\" in input_storage_location:\n",
        "    working_folder = os.path.join(\"/content/drive/MyDrive/\", project_name)\n",
        "else:\n",
        "    working_folder = os.path.join(\"/content\", project_name)\n",
        "\n",
        "# Check if the working_folder exists\n",
        "if not check_directory_exists(working_folder):\n",
        "    print(f\"The directory '{working_folder}' does not exist.\")\n",
        "\n",
        "\n",
        "print(f\"There are {countNumberOfFilesInFolder(working_folder)} files in {working_folder}\")\n",
        "\n",
        "screenshots_output_folder = \"\" #@param {type:\"string\"}\n",
        "output_storage_location = \"Store in Google Drive (/content/drive/MyDrive/)\" #@param [\"Store in colab (/content/)\", \"Store in Google Drive (/content/drive/MyDrive/)\"]\n",
        "default_output_folder = f\"{video_file_name}_output\"\n",
        "\n",
        "cleaned_default_output_folder = clean_string(default_output_folder)\n",
        "\n",
        "screenshots_output_folder = screenshots_output_folder or cleaned_default_output_folder\n",
        "#@markdown Adjust how often you want to screenshot frames. (Example: 30 FPS for 1 minute is 1800 screenshots)\n",
        "frame_interval = 10 #@param {type:\"integer\"}\n",
        "#@markdown NOTE: Progress bar is not accurate if you adjust the frame_interval\n",
        "\n",
        "#@markdown Check this box if you want to delete the output folder before creating new output\n",
        "delete_output_flag = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Automatic Zip Output Options\n",
        "zip_output = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Check if video_file_name is empty\n",
        "assert video_file_name, \"Error: video_file_name is empty. Please provide a valid file name.\"\n",
        "\n",
        "\n",
        "def delete_output_directory(output_directory):\n",
        "    if os.path.exists(output_directory):\n",
        "        subprocess.run(['rm', '-r', output_directory])\n",
        "        print(f\"Output directory '{output_directory}' deleted.\")\n",
        "\n",
        "def run_ffmpeg_command(input_video, screenshots_output_folder, frame_interval):\n",
        "    # Create the output directory if it doesn't exist\n",
        "    subprocess.run(['mkdir', '-p', screenshots_output_folder])\n",
        "\n",
        "    # Get total number of frames in the video\n",
        "    ffprobe_command = f'ffprobe -v error -select_streams v:0 -show_entries stream=nb_frames -of default=nokey=1:noprint_wrappers=1 \"{input_video}\"'\n",
        "    total_frames = int(subprocess.check_output(shlex.split(ffprobe_command)).decode('utf-8').strip())\n",
        "\n",
        "    # FFmpeg command to extract frames with progress bar\n",
        "    ffmpeg_command = f'ffmpeg -i \"{input_video}\" -vf \"select=not(mod(n\\,{frame_interval})),setpts=N/FRAME_RATE/TB\" -vsync vfr \"{screenshots_output_folder}/output_frames_%04d.png\" -progress pipe:1'\n",
        "\n",
        "    # Run FFmpeg command with progress bar\n",
        "    process = subprocess.Popen(shlex.split(ffmpeg_command), stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, bufsize=1, universal_newlines=True)\n",
        "\n",
        "    # Parse progress information\n",
        "    duration_pattern = re.compile(r\"Duration: (\\d+:\\d+:\\d+\\.\\d+),\")\n",
        "    time_pattern = re.compile(r\"time=(\\d+:\\d+:\\d+\\.\\d+)\")\n",
        "    total_duration = None\n",
        "\n",
        "    with tqdm(total=total_frames, unit=\"frame\", unit_scale=True, desc=\"Processing\") as pbar:\n",
        "        for line in process.stderr:\n",
        "            duration_match = duration_pattern.search(line)\n",
        "            time_match = time_pattern.search(line)\n",
        "\n",
        "            if duration_match:\n",
        "                total_duration = duration_match.group(1)\n",
        "\n",
        "            if time_match and total_duration:\n",
        "                current_time = time_match.group(1)\n",
        "                progress_percentage = (time_to_seconds(current_time) / time_to_seconds(total_duration)) * 100\n",
        "                frames_processed = int(progress_percentage * total_frames / 100)\n",
        "                pbar.update(frames_processed - pbar.n)\n",
        "\n",
        "    # Wait for the process to finish\n",
        "    process.wait()\n",
        "\n",
        "    # Check for errors\n",
        "    if process.returncode != 0:\n",
        "        print(f\"\\nError: FFmpeg process failed with return code {process.returncode}\")\n",
        "    else:\n",
        "        print(f\"\\nFrames extracted successfully. Output directory: {screenshots_output_folder}\")\n",
        "\n",
        "def time_to_seconds(time_str):\n",
        "    h, m, s = map(float, time_str.split(':'))\n",
        "    return h * 3600 + m * 60 + s\n",
        "\n",
        "\n",
        "input_video_path = os.path.join(working_folder, video_file_name)\n",
        "#set default location to google drive\n",
        "output_frames_directory = os.path.join(working_folder, screenshots_output_folder)\n",
        "\n",
        "if output_storage_location == \"Store in colab (/content/)\":\n",
        "    # Code for storing in colab session\n",
        "    storage_path = \"/content/\"\n",
        "    output_frames_directory = os.path.join(storage_path, project_name, screenshots_output_folder)\n",
        "    print(\"Storing in colab session.\")\n",
        "\n",
        "elif output_storage_location == \"Store in Google Drive (/content/drive/MyDrive/)\":\n",
        "    # Code for storing in Google Drive\n",
        "    storage_path = \"/content/drive/MyDrive/\"\n",
        "    output_frames_directory = os.path.join(storage_path, project_name, screenshots_output_folder)\n",
        "    print(\"Storing in Google Drive.\")\n",
        "\n",
        "\n",
        "if (delete_output_flag):\n",
        "  print(\"delete_output_flag is true\")\n",
        "  delete_output_directory(output_frames_directory)\n",
        "\n",
        "run_ffmpeg_command(input_video_path, output_frames_directory, frame_interval)\n",
        "\n",
        "print(f\"There are {countNumberOfFilesInFolder(output_frames_directory)} images in the output directory\")\n",
        "\n",
        "\n",
        "\n",
        "if (zip_output):\n",
        "  print(\"_\" * 50) #Print Horizontal bar\n",
        "  zip_output_storage_location = \"Store in colab (/content/)\" #@param [\"Store in colab (/content/)\", \"Store in Google Drive (/content/drive/MyDrive/)\"]\n",
        "\n",
        "  if zip_output_storage_location == \"Store in colab (/content/)\":\n",
        "      # Code for storing in colab session\n",
        "      storage_path = \"/content/\"\n",
        "      output_zip_directory = os.path.join(storage_path, screenshots_output_folder)\n",
        "      print(f\"Zipping output in Google Drive: {output_zip_directory}\")\n",
        "\n",
        "  elif zip_output_storage_location == \"Store in Google Drive (/content/drive/MyDrive/)\":\n",
        "      # Code for storing in Google Drive\n",
        "      storage_path = \"/content/drive/MyDrive/\"\n",
        "      output_zip_directory = os.path.join(storage_path, project_name, screenshots_output_folder)\n",
        "      print(f\"Zipping output in Google Colab: {output_zip_directory}\")\n",
        "\n",
        "  folder_to_zip = output_frames_directory\n",
        "  zip_output_path = output_zip_directory\n",
        "\n",
        "  zip_folder(folder_to_zip, zip_output_path)\n"
      ],
      "metadata": {
        "id": "nuIUa4icWw8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Zip the Screenshots Output Folder\n",
        "\n",
        "zip_output_storage_location = \"Store in colab (/content/)\" #@param [\"Store in colab (/content/)\", \"Store in Google Drive (/content/drive/MyDrive/)\"]\n",
        "\n",
        "if zip_output_storage_location == \"Store in colab (/content/)\":\n",
        "    # Code for storing in colab session\n",
        "    storage_path = \"/content/\"\n",
        "    output_zip_directory = os.path.join(storage_path, screenshots_output_folder)\n",
        "    print(f\"Zipping output in Google Drive: {output_zip_directory}\")\n",
        "\n",
        "elif zip_output_storage_location == \"Store in Google Drive (/content/drive/MyDrive/)\":\n",
        "    # Code for storing in Google Drive\n",
        "    storage_path = \"/content/drive/MyDrive/\"\n",
        "    output_zip_directory = os.path.join(storage_path, project_name, screenshots_output_folder)\n",
        "    print(f\"Zipping output in Google Colab: {output_zip_directory}\")\n",
        "\n",
        "folder_to_zip = output_frames_directory\n",
        "zip_output_path = output_zip_directory\n",
        "\n",
        "zip_folder(folder_to_zip, zip_output_path)"
      ],
      "metadata": {
        "id": "EEyWh4NZh2hF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}